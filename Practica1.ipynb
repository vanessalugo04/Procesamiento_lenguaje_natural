{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "39a15c7e-a466-45ec-9324-ffa306d6b330",
      "metadata": {
        "id": "39a15c7e-a466-45ec-9324-ffa306d6b330"
      },
      "outputs": [],
      "source": [
        "# EL ESPACIO VA A MARCAR LA DIFERENCIA ENTRE UNA PALABRA Y OTRA\n",
        "#CUALQUIERA DE LOS TOKENIZADORES A C O C ++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f5c16b0-9325-4584-837f-c87261df8524",
      "metadata": {
        "id": "6f5c16b0-9325-4584-837f-c87261df8524"
      },
      "outputs": [],
      "source": [
        "#comenzamos importando las librerias necesarias\n",
        "\n",
        "import string\n",
        "import time\n",
        "import tracemalloc\n",
        "\n",
        "#definimos las cadenas de prueba\n",
        "cadena1 = 'Ma@rc/o, Ant#oni1#o@'\n",
        "cadena2 = 'Marco, Antonio'\n",
        "cadena3 = 'M@rco Ant#oni1#o'\n",
        "cadena4 = 'Marco @__Antonio'\n",
        "cadena5 = 'Mar__co Antonio%%'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cd4cad49-bb9e-4348-a0c0-5689e02dc717",
      "metadata": {
        "id": "cd4cad49-bb9e-4348-a0c0-5689e02dc717",
        "outputId": "9fd46068-6b69-4ae5-ac3f-d6ec2e84d86c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
          ]
        }
      ],
      "source": [
        "def tokenizador4(texto):\n",
        "  ascii_acentos = [225, 233, 237, 243, 250,  193, 201, 205, 211, 218,  241, 209]\n",
        "  token = \"\"\n",
        "  tokens = [None]*len(texto)\n",
        "  j=0\n",
        "  #si es una letra, se pasa, en cualquier otro caso se añade un punto final\n",
        "  if ord(texto[-1]) >= 97 and ord(texto[-1]) <= 122 :\n",
        "    pass\n",
        "  else:\n",
        "    texto = texto + '.'\n",
        "\n",
        "# RECORRER EL TEXTO COMO SI FUERA UN ARREGLO. CONSIDERANDO FUNCIONES SEPARADAS POR PUNTO\n",
        "\n",
        "  for i in range (len(texto)):\n",
        "  #dependiendo de su codigo ascii, filtramos MINUSCULAS , MAYUSCULAS, NUMEROS\n",
        "    if ((ord(texto[i]) >= 97 and ord(texto[i]) <= 122) or (ord(texto[i]) >= 65 and ord(texto[i]) <= 90) or (ord(texto[i]) >= 48 and ord(texto[i]) <= 57) ):\n",
        "      #ACENTOS\n",
        "      if ord(texto[i]) in ascii_acentos:\n",
        "        token += texto[i]\n",
        "      elif token==\"\":\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "      tokens[j] = token\n",
        "      token = \"\"\n",
        "      j+=1\n",
        "\n",
        "  return tokens[0:j]\n",
        "\n",
        "texto = \"Ló5s 10 alúmn1os de 1 PLN2 tienen poca imaginación. Es lamentable.\"\n",
        "\n",
        "print(tokenizador4(texto))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fd9e9964-75aa-4564-9edb-0e9b36336e3c",
      "metadata": {
        "id": "fd9e9964-75aa-4564-9edb-0e9b36336e3c",
        "outputId": "81a61407-dcb7-490e-8660-2e7a74f6465e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Marco', 'Antonio']\n"
          ]
        }
      ],
      "source": [
        "def es_valido(caracter):\n",
        "    c = ord(caracter)\n",
        "\n",
        "    #verificamos sea MINUSCULA, MAYUSCULA, NUMERO\n",
        "    if (c >= 97 and c <= 122)  or (c >= 65 and c <= 90) or  (c >= 48 and c <= 57):\n",
        "        return True\n",
        "\n",
        "    acentos = [225, 233, 237, 243, 250,  193, 201, 205, 211, 218,  241, 209]\n",
        "    # checamos acentos\n",
        "    if c in acentos:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def tokenizador4(texto):\n",
        "    token = ''\n",
        "    tokens = [None]*len(texto)\n",
        "    j=0\n",
        "\n",
        "    for i in range(len(texto)):\n",
        "        if es_valido(texto[i]):\n",
        "            token += texto[i]\n",
        "        else:\n",
        "            if token != \"\":\n",
        "                tokens[j] = token\n",
        "                j = j+1\n",
        "                token = ''\n",
        "    if token != '': #revisar la ultima letra\n",
        "        tokens[j] = token\n",
        "        j = j+1\n",
        "\n",
        "    return tokens[0:j]\n",
        "\n",
        "texto = \"Ló5@@s 10 alúmn1os__ de 1 PLN2 tienen poca imaginación.\"\n",
        "#llamamos la funcionsita\n",
        "print(tokenizador4(cadena4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mcLahs65QkOE",
      "metadata": {
        "id": "mcLahs65QkOE"
      },
      "source": [
        "c) Modifique el tokenizador para que,si hay caracteres especiales o numeros entre letras tokenice.Para determinar si hay otra palabra deberá haber un espacio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c7015a3-40bd-426d-8256-f1cce9e25d29",
      "metadata": {
        "id": "7c7015a3-40bd-426d-8256-f1cce9e25d29"
      },
      "outputs": [],
      "source": [
        "def tokenizador_modificado(texto):\n",
        "\n",
        "    ascii_acentos = [225,233,237,243,250,193,201,205,211,218,241,209,252,220]\n",
        "\n",
        "    tokens = []\n",
        "    palabra = \"\"\n",
        "\n",
        "    for i in range(len(texto)):\n",
        "        c = texto[i]\n",
        "        codigo = ord(c)\n",
        "\n",
        "        #letras minúsculas\n",
        "        if codigo >= 97 and codigo <= 122:\n",
        "            palabra = palabra + c\n",
        "\n",
        "        #letras mayúsculas\n",
        "        elif codigo >= 65 and codigo <= 90:\n",
        "            palabra = palabra + c\n",
        "\n",
        "        #letras con acento\n",
        "        elif codigo in ascii_acentos:\n",
        "            palabra = palabra + c\n",
        "\n",
        "        #espacio → termina palabra\n",
        "        elif codigo == 32:\n",
        "            if palabra != \"\":\n",
        "                tokens = tokens + [palabra]\n",
        "                palabra = \"\"\n",
        "\n",
        "        # números y símbolos → se ignoran (NO separan palabra)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    #agregar última palabra\n",
        "    if palabra != \"\":\n",
        "        tokens = tokens + [palabra]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fqhuAMQrRMX8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqhuAMQrRMX8",
        "outputId": "d983f085-6776-479a-eb87-ee4b0b69830f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Marco', 'Antonio']\n"
          ]
        }
      ],
      "source": [
        "resultado = tokenizador_modificado(cadena1)\n",
        "\n",
        "print(resultado)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}